{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3F6Pt9qWgWMg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, input, output):\n",
        "        super().__init__()\n",
        "        # this is the first half part\n",
        "\n",
        "        #   encoder part\n",
        "\n",
        "        self.conv1 = nn.Conv2d(input, 64, kernel_size= 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size= 3,  padding=1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size= 3,  padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size= 3,  padding=1)\n",
        "\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size= 3,  padding=1)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size= 3,  padding=1)\n",
        "\n",
        "\n",
        "        self.conv7 = nn.Conv2d(256, 512, kernel_size= 3, padding=1)\n",
        "        self.conv8 = nn.Conv2d(512, 512, kernel_size= 3,  padding=1)\n",
        "\n",
        "\n",
        "        #bottleneck\n",
        "\n",
        "        self.conv9 = nn.Conv2d(512, 1024, kernel_size= 3,  padding=1)\n",
        "        self.conv10 = nn.Conv2d(1024, 1024, kernel_size= 3,  padding=1)\n",
        "\n",
        "\n",
        "\n",
        "        #   decoder part\n",
        "\n",
        "        self.conv11 = nn.Conv2d(1024, 512, kernel_size= 3, padding=1)\n",
        "        self.conv12 = nn.Conv2d(512, 512, kernel_size= 3, padding=1)\n",
        "\n",
        "\n",
        "        self.conv13 = nn.Conv2d(512, 256, kernel_size= 3, padding=1)\n",
        "        self.conv14 = nn.Conv2d(256, 256, kernel_size= 3, padding=1)\n",
        "\n",
        "\n",
        "\n",
        "        self.conv15 = nn.Conv2d(256, 128, kernel_size= 3, padding=1)\n",
        "        self.conv16 = nn.Conv2d(128, 128, kernel_size= 3, padding=1)\n",
        "\n",
        "        self.conv17 = nn.Conv2d(128, 64, kernel_size= 3, padding=1)\n",
        "        self.conv18 = nn.Conv2d(64, 64, kernel_size= 3, padding=1)\n",
        "\n",
        "        # output part\n",
        "        self.conv19 = nn.Conv2d(64, output, kernel_size= 1)\n",
        "\n",
        "\n",
        "        # upsamplingtranspose part\n",
        "        self.upsam1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.upsam2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.upsam3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.upsam4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        # we will use ReLU for our activation function\n",
        "        self.activation = nn.ReLU()\n",
        "        # for downsampling\n",
        "        self.maxpooling = nn.MaxPool2d(kernel_size=2, stride =2)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #downsampling part\n",
        "        x1 = self.activation(self.conv2(self.activation(self.conv1(x))))\n",
        "        x2= self.maxpooling(x1)\n",
        "\n",
        "\n",
        "        x3= self.activation(self.conv4(self.activation(self.conv3(x2))))\n",
        "        x4= self.maxpooling(x3)\n",
        "\n",
        "        x5= self.activation(self.conv6(self.activation(self.conv5(x4))))\n",
        "        x6= self.maxpooling(x5)\n",
        "\n",
        "        x7= self.activation(self.conv8(self.activation(self.conv7(x6))))\n",
        "        x8= self.maxpooling(x7)\n",
        "\n",
        "        # bottleneck part\n",
        "\n",
        "\n",
        "        x9 =  self.activation(self.conv10(self.activation(self.conv9(x8))))\n",
        "\n",
        "\n",
        "\n",
        "        #upsampling part\n",
        "        x = self.upsam1(x9)\n",
        "        x = torch.cat([x, x7], dim=1)\n",
        "        x = self.activation(self.conv12(self.activation(self.conv11(x))))\n",
        "\n",
        "        x = self.upsam2(x)\n",
        "        x = torch.cat([x, x5], dim=1)\n",
        "        x = self.activation(self.conv14(self.activation(self.conv13(x))))\n",
        "\n",
        "        x = self.upsam3(x)\n",
        "        x = torch.cat([x, x3], dim=1)\n",
        "        x = self.activation(self.conv16(self.activation(self.conv15(x))))\n",
        "\n",
        "        x = self.upsam4(x)\n",
        "        x = torch.cat([x, x1], dim=1)\n",
        "        x = self.activation(self.conv18(self.activation(self.conv17(x))))\n",
        "\n",
        "        return self.conv19(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = UNet(input=3, output=1)\n",
        "print(model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI8l0g0Zg7od",
        "outputId": "7d93d902-9cf6-46d6-f0f5-8cc6a2e0ce80"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv9): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv10): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv11): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv13): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv15): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv17): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv19): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (upsam1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (upsam2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (upsam3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (upsam4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (activation): ReLU()\n",
            "  (maxpooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl9n5vSitmTG",
        "outputId": "8fbbb1ef-987e-4850-aeaa-f5f6e571d670"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "import torch\n",
        "\n",
        "# Create an instance of your model\n",
        "model = UNet(input=3, output=1)  # 3 input channels for RGB, 1 output channel for binary segmentation\n",
        "\n",
        "# Display the summary of the model\n",
        "summary(model, (3, 128, 128))  # Corrected input shape (3 channels for RGB, 64x64 image size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2Di4VTyuNhE",
        "outputId": "962d573d-1745-493a-d18c-5fa59db7ae50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           1,792\n",
            "              ReLU-2         [-1, 64, 128, 128]               0\n",
            "            Conv2d-3         [-1, 64, 128, 128]          36,928\n",
            "              ReLU-4         [-1, 64, 128, 128]               0\n",
            "         MaxPool2d-5           [-1, 64, 64, 64]               0\n",
            "            Conv2d-6          [-1, 128, 64, 64]          73,856\n",
            "              ReLU-7          [-1, 128, 64, 64]               0\n",
            "            Conv2d-8          [-1, 128, 64, 64]         147,584\n",
            "              ReLU-9          [-1, 128, 64, 64]               0\n",
            "        MaxPool2d-10          [-1, 128, 32, 32]               0\n",
            "           Conv2d-11          [-1, 256, 32, 32]         295,168\n",
            "             ReLU-12          [-1, 256, 32, 32]               0\n",
            "           Conv2d-13          [-1, 256, 32, 32]         590,080\n",
            "             ReLU-14          [-1, 256, 32, 32]               0\n",
            "        MaxPool2d-15          [-1, 256, 16, 16]               0\n",
            "           Conv2d-16          [-1, 512, 16, 16]       1,180,160\n",
            "             ReLU-17          [-1, 512, 16, 16]               0\n",
            "           Conv2d-18          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-19          [-1, 512, 16, 16]               0\n",
            "        MaxPool2d-20            [-1, 512, 8, 8]               0\n",
            "           Conv2d-21           [-1, 1024, 8, 8]       4,719,616\n",
            "             ReLU-22           [-1, 1024, 8, 8]               0\n",
            "           Conv2d-23           [-1, 1024, 8, 8]       9,438,208\n",
            "             ReLU-24           [-1, 1024, 8, 8]               0\n",
            "  ConvTranspose2d-25          [-1, 512, 16, 16]       2,097,664\n",
            "           Conv2d-26          [-1, 512, 16, 16]       4,719,104\n",
            "             ReLU-27          [-1, 512, 16, 16]               0\n",
            "           Conv2d-28          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-29          [-1, 512, 16, 16]               0\n",
            "  ConvTranspose2d-30          [-1, 256, 32, 32]         524,544\n",
            "           Conv2d-31          [-1, 256, 32, 32]       1,179,904\n",
            "             ReLU-32          [-1, 256, 32, 32]               0\n",
            "           Conv2d-33          [-1, 256, 32, 32]         590,080\n",
            "             ReLU-34          [-1, 256, 32, 32]               0\n",
            "  ConvTranspose2d-35          [-1, 128, 64, 64]         131,200\n",
            "           Conv2d-36          [-1, 128, 64, 64]         295,040\n",
            "             ReLU-37          [-1, 128, 64, 64]               0\n",
            "           Conv2d-38          [-1, 128, 64, 64]         147,584\n",
            "             ReLU-39          [-1, 128, 64, 64]               0\n",
            "  ConvTranspose2d-40         [-1, 64, 128, 128]          32,832\n",
            "           Conv2d-41         [-1, 64, 128, 128]          73,792\n",
            "             ReLU-42         [-1, 64, 128, 128]               0\n",
            "           Conv2d-43         [-1, 64, 128, 128]          36,928\n",
            "             ReLU-44         [-1, 64, 128, 128]               0\n",
            "           Conv2d-45          [-1, 1, 128, 128]              65\n",
            "================================================================\n",
            "Total params: 31,031,745\n",
            "Trainable params: 31,031,745\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 140.88\n",
            "Params size (MB): 118.38\n",
            "Estimated Total Size (MB): 259.44\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}